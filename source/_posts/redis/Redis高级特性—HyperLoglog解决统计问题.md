---
title: Redis高级特性—HyperLoglog解决统计问题
tags:
  - redis
categories:
	- redis
toc: true
toc_number: true
cover:  https://img-blog.csdnimg.cn/e642cbd4bb8b4182a58da81cf8636d87.png
---


# 简介
` HyperLogLog `是用来做**基数统计**的算法，`HyperLogLog `的优点是，在输入元素的数量或者**体积非常非常大**时，计算基数所需的空间总是`固定 `的、并且是`很小`的。在 `Redis `里面，每个` HyperLogLog` 键只需要花费 `12 KB` 内存，就可以计算接近 `2^64 `个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为` HyperLogLog` 只会根据输入元素来计算基数，而`不会储存输入元素本身`，所以 `HyperLogLog` 不能像集合那样，返回输入的各个元素。但要注意，`HyperLogLog `是统计规则是基于概率完成的，不是非常准确，标准误算率是 `0.81%`。
# 关于基数统计
基数统计通常是用来统计一个集合中**不重复**的元素个数。
思考这样的一个场景： 开发维护一个大型的网站，有一天老板找产品经理要网站上每个网页的` UV`(每个用户每天只记录一次)，然后让你来开发这个统计模块，你会如何实现？
- 统计`PV(点一次记一次)`，可以给每个页面一个单独的`redis`计数器。
- 统计`UV(每个用户每天只记录一次)`
   - 每个页面一个`zset`保存用户`ID`，存储空间大，聚合麻烦（·老板知道估计打死·。。。）；
   - `bitmap`:用位数组来表示用户`ID`是否出现，每个用户`ID`对应一位，所需的总内存为`n bit`。能大大减少内存占用且位操作迅速，统计1亿个数据的基数值，大约需要内存`100000000/8/1024/1024 ≈ 12M`。统计`一个对象`的基数值需要`12M`，如果统计`10000`个对象，就需要将近`120G`；
 -  概率算法 `HyperLogLog`：使用**概率算法**算是一个不错的解决方案。概率算法不直接存储数据集合本身，通过一定的概率统计方法预估基数值，这种方法可以**大大节省内存**，同时保证**误差控制在一定范围内**。

# 常见命令
## pfadd 添加
- 影响基数估值则返回1否则返回0.若key不存在则创建
- 时间复杂度O(1)
```
127.0.0.1:6379> pfadd web:index user1
(integer) 1
```
## pfcount 获得基数值

```
127.0.0.1:6379>pfadd web:index user1
(integer) 1
127.0.0.1:6379> pfcount web:index
(integer) 1
```

## pfmerge 合并多个key

```
127.0.0.1:6379>pfadd web:index:1 user1
(integer) 1
127.0.0.1:6379> pfcount web:index:1
(integer) 1
127.0.0.1:6379> pfadd web:index:2 user2
(integer) 1
127.0.0.1:6379> pfcount web:index:2
(integer) 1
127.0.0.1:6379> pfmerge web:index web:index:1 web:index:2
OK
127.0.0.1:6379> pfcount web:index 
(integer) 2
```

# 应用场景
- 百万级网页 `UV `计数
- 统计每日访问 `IP` 数
- 统计在线百万级用户数
- 统计用户每天搜索不同词条的个数

# 注意
- 基数不大，数据量不大就用不上，会有点大材小用浪费空间;
- 有局限性，就是只能统计基数数量，而没办法去知道具体的内容是什么;
- 和`bitmap`相比，属于两种特定统计情况，简单来说，`HyperLogLog `去重比` bitmap` 方便很多;
- 一般可以`bitmap`和`hyperloglog`配合使用，`bitmap`标识哪些用户活跃，`hyperloglog`计数;

# pf 的内存占用为什么是 12k ？
在 `Redis `的 `HyperLogLog`实现中用到的是 `16384 `个桶，也就是 `2^14`，每个桶的 `maxbits` 需要 `6 `个 `bits` 来存储，最大可以表示 `maxbits`=`63`，于是总共占用内存就是 `2^14 * 6 / 8 = 12k`字节。

# 个人总结：
- 目的是做**基数统计**，故不是集合，不会保存元数据，只记录**数量**而不是数值;
- 耗空间极小，支持输入非常体积的数据量,最终数值存在一定误差;
- redis中每个`hyperloglog key`占用了`12K`的内存用于标记基数;
- `pfadd`命令并不会一次性分配`12k`内存，而是随着基数的增加而逐渐增加内存分配；而`pfmerge`操作则会将`source key`合并后存储在`12k`大小的`key`中，这由`hyperloglog`合并操作的原理（两个hyperloglog`合并时需要单独比较每个桶的值）可以很容易理解。
- 误差说明：`Redis `对 `HyperLogLog` 的存储进行了优化，在计数比较小时，它的存储空间采用**稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩**阵，才会占用 `12k `的空间。
